{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1a211a-31a4-4caa-ba3b-e7e0efca56fb",
   "metadata": {
    "id": "0c1a211a-31a4-4caa-ba3b-e7e0efca56fb"
   },
   "source": [
    "<h1><center> Домашняя работа #3</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f7eb14-6ab1-4e3d-ae2c-78102246b07e",
   "metadata": {
    "id": "22f7eb14-6ab1-4e3d-ae2c-78102246b07e"
   },
   "source": [
    "Задача:\n",
    "\n",
    "- еализуйте алгоритм А2С (Advanced Actor Critic)\n",
    "- обучите агента в среде Car Racing;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69a97b-473f-4ed3-a14e-f7dc3891e205",
   "metadata": {
    "id": "ec69a97b-473f-4ed3-a14e-f7dc3891e205"
   },
   "source": [
    "Описание задачи на сайте Gymnasium ([ссылка](https://gymnasium.farama.org/environments/box2d/lunar_lander/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa295485-0d74-4554-9d22-a7b399341033",
   "metadata": {
    "id": "fa295485-0d74-4554-9d22-a7b399341033"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "MCvrGnEH-I2P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCvrGnEH-I2P",
    "outputId": "90feb585-5898-4b14-f37f-62fa1a2668e6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sat Dec  6 11:00:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   54C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4958e80b-33b8-4e4d-ab85-e8b088b91e58",
   "metadata": {
    "id": "4958e80b-33b8-4e4d-ab85-e8b088b91e58"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d5ca49-7e2c-489d-84d5-c235a28b29a0",
   "metadata": {
    "id": "32d5ca49-7e2c-489d-84d5-c235a28b29a0"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from tqdm import trange\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Commented since the code is commented too\n",
    "# from stable_baselines3 import A2C\n",
    "# from stable_baselines3.common.callbacks import BaseCallback\n",
    "# from stable_baselines3.common.env_util import make_vec_env\n",
    "# from stable_baselines3.common.vec_env import (\n",
    "#     DummyVecEnv,\n",
    "#     VecMonitor,\n",
    "#     VecFrameStack,\n",
    "#     VecTransposeImage,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fbf708-8acf-4e2a-ada4-443ea1ac5a2e",
   "metadata": {
    "id": "46fbf708-8acf-4e2a-ada4-443ea1ac5a2e"
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from src.torch_utils import get_device, preprocess_state, transform_state_to_tensor\n",
    "from src.actor_critic import (\n",
    "    ActorNet,\n",
    "    ValueNet,\n",
    "    compute_returns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58fa3845-b42c-46aa-a1f7-9912691de4b3",
   "metadata": {
    "id": "58fa3845-b42c-46aa-a1f7-9912691de4b3"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff628a08-df21-4209-8789-2be403d184ed",
   "metadata": {
    "id": "ff628a08-df21-4209-8789-2be403d184ed"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba761d-d05e-4492-b134-3d02fe94777b",
   "metadata": {
    "id": "f5ba761d-d05e-4492-b134-3d02fe94777b"
   },
   "source": [
    "**Observation space:**\n",
    "\n",
    "A top-down 96x96 RGB image of the car and race track.\n",
    "\n",
    "**Actions:**\n",
    "\n",
    "- 0: steering, -1 is full left, +1 is full right\n",
    "- 1: gas\n",
    "- 2: braking\n",
    "\n",
    "The three numbers (in order) are:\n",
    "\n",
    "1. Steering\n",
    "   - Range: [-1.0, 1.0]\n",
    "   - Negative values: turn left\n",
    "   - Positive values: turn right\n",
    "2. Acceleration (Gas)\n",
    "   -  Range: [0.0, 1.0]\n",
    "   - 0 = no acceleration\n",
    "   - 1 = full acceleration\n",
    "3. Brake\n",
    "    -  Range: [0.0, 1.0]\n",
    "   - 0 = no braking\n",
    "   - 1 = full braking\n",
    "\n",
    "---\n",
    "\n",
    "Example Actions:\n",
    "\n",
    "- [0.0, 0.5, 0.0] → Go straight, accelerate at 50% power, no brake.\n",
    "- [-0.8, 0.1, 0.0] → Sharp left turn, low acceleration.\n",
    "- [0.3, 0.0, 0.7] → Gentle right turn, no gas, brake at 70%.\n",
    "\n",
    "**Rewards:**\n",
    "\n",
    "The reward is -0.1 every frame and +1000/N for every track tile visited, where N is the total number of tiles visited in the track. For example, if you have finished in 732 frames, your reward is 1000 - 0.1*732 = 926.8 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06NVw_Hg-DQ3",
   "metadata": {
    "id": "06NVw_Hg-DQ3"
   },
   "outputs": [],
   "source": [
    "# %pip install swig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "qJxtajHf-FTy",
   "metadata": {
    "id": "qJxtajHf-FTy"
   },
   "outputs": [],
   "source": [
    "# %pip install Box2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d8f7fc-271f-41fd-aaad-ce9b4df2d075",
   "metadata": {
    "id": "34d8f7fc-271f-41fd-aaad-ce9b4df2d075",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "## Версия в stable_baselines3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df5b1e-095f-4a09-8630-ebe494ccc91a",
   "metadata": {
    "id": "38df5b1e-095f-4a09-8630-ebe494ccc91a"
   },
   "source": [
    "Мы используем CnnPolicy, так как нам нужна сверточная нейросеть для обработки изображения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f529e9e-d8c8-45e7-b08b-87a110b24fd9",
   "metadata": {
    "id": "2f529e9e-d8c8-45e7-b08b-87a110b24fd9"
   },
   "source": [
    "Обучение идет, но нужно очень много шагов. Нормально не работает. -> Код закоментирован"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6914005-bf1b-4d76-9d51-6f7f55b04315",
   "metadata": {
    "id": "a6914005-bf1b-4d76-9d51-6f7f55b04315"
   },
   "outputs": [],
   "source": [
    "# env = make_vec_env(\n",
    "#     env_id=\"CarRacing-v3\",\n",
    "#     n_envs=4,\n",
    "#     env_kwargs={\"continuous\": True, 'max_episode_steps': 1_000},\n",
    "#     vec_env_cls=DummyVecEnv\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab4935f-fee4-49eb-865e-fb20e8ad2e94",
   "metadata": {
    "id": "4ab4935f-fee4-49eb-865e-fb20e8ad2e94"
   },
   "outputs": [],
   "source": [
    "# env = VecMonitor(env)\n",
    "# env = VecFrameStack(env, n_stack=4)\n",
    "# env = VecTransposeImage(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bad25787-2f43-45cf-a2e5-d0e1a3cefe56",
   "metadata": {
    "id": "bad25787-2f43-45cf-a2e5-d0e1a3cefe56"
   },
   "outputs": [],
   "source": [
    "# model = A2C(\n",
    "#     policy=\"CnnPolicy\",\n",
    "#     n_steps=512,\n",
    "#     gamma=0.99,\n",
    "#     learning_rate=3e-4,\n",
    "#     max_grad_norm=0.5,\n",
    "#     use_rms_prop=True,\n",
    "#     vf_coef=0.25,\n",
    "#     ent_coef=0.01,\n",
    "#     gae_lambda=0.95,\n",
    "#     normalize_advantage=True,\n",
    "#     tensorboard_log=None,\n",
    "#     env=env,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd734f3d-fd53-4e31-bfa4-d72d2e42b470",
   "metadata": {
    "id": "cd734f3d-fd53-4e31-bfa4-d72d2e42b470"
   },
   "outputs": [],
   "source": [
    "# model.learn(\n",
    "#     total_timesteps=250_000,\n",
    "#     progress_bar=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "122eda0b-709d-4e6b-99f6-d34a53e09d59",
   "metadata": {
    "id": "122eda0b-709d-4e6b-99f6-d34a53e09d59"
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir ./a2c_carracing_tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28e9c69c-a245-4451-b26d-b951b1644257",
   "metadata": {
    "id": "28e9c69c-a245-4451-b26d-b951b1644257"
   },
   "outputs": [],
   "source": [
    "# model.save(\"car_racing_baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c1f2f56-369f-413e-9cd5-d88050ac6351",
   "metadata": {
    "id": "5c1f2f56-369f-413e-9cd5-d88050ac6351"
   },
   "outputs": [],
   "source": [
    "# model = A2C.load(\"car_racing_baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f9eb07-23cc-42c6-a983-3fc42839c6f4",
   "metadata": {
    "id": "c3f9eb07-23cc-42c6-a983-3fc42839c6f4"
   },
   "outputs": [],
   "source": [
    "# def create_agent_env():\n",
    "#     def _init():\n",
    "#         env = gym.make(\n",
    "#             \"CarRacing-v3\",\n",
    "#             continuous=True,\n",
    "#             domain_randomize=False,\n",
    "#             lap_complete_percent=0.95,\n",
    "#             max_episode_steps=5_000,\n",
    "#             render_mode=\"rgb_array\",\n",
    "#         )\n",
    "#         return env\n",
    "#     env = DummyVecEnv([_init])\n",
    "#     env = VecFrameStack(env, n_stack=4)\n",
    "#     env = VecTransposeImage(env)\n",
    "#     return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60cd1101-c067-461c-8d01-13822b74af83",
   "metadata": {
    "id": "60cd1101-c067-461c-8d01-13822b74af83"
   },
   "outputs": [],
   "source": [
    "# agent_env = create_agent_env()\n",
    "# render_env = gym.make(\n",
    "#     \"CarRacing-v3\",\n",
    "#     continuous=True,\n",
    "#     domain_randomize=False,\n",
    "#     lap_complete_percent=0.95,\n",
    "#     max_episode_steps=5_000,\n",
    "#     render_mode=\"human\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03e6b2fb-246e-4fdf-9675-7c612409969e",
   "metadata": {
    "id": "03e6b2fb-246e-4fdf-9675-7c612409969e"
   },
   "outputs": [],
   "source": [
    "# obs_agent = agent_env.reset()\n",
    "# obs_render, _ = render_env.reset()\n",
    "\n",
    "# done = False\n",
    "# score = 0\n",
    "\n",
    "# while not done:\n",
    "#     action, _ = model.predict(obs_agent, deterministic=True)\n",
    "#     obs_agent, reward, done, _ = agent_env.step(action)\n",
    "#     _, _, _,_, _ = render_env.step(action[0])\n",
    "#     score += reward[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a74883-db9c-4a1b-bc11-85fa8b82e2e8",
   "metadata": {
    "id": "b1a74883-db9c-4a1b-bc11-85fa8b82e2e8"
   },
   "outputs": [],
   "source": [
    "# agent_env.close()\n",
    "# render_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf7468c-5260-4203-b4de-bebdd36f995e",
   "metadata": {
    "id": "4cf7468c-5260-4203-b4de-bebdd36f995e"
   },
   "source": [
    "---\n",
    "## Свой класс"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2140c-0cea-41b6-9f3b-f5979c735e7f",
   "metadata": {
    "id": "27d2140c-0cea-41b6-9f3b-f5979c735e7f"
   },
   "source": [
    "## Реализация:\n",
    "1. Инициализируем случайным образом сети политики (actor) $\\pi^{\\mu}(a|s)|_{\\theta^{\\mu}}$ и V-функции (critic) $V^{\\theta}(s)|_{\\theta^{V}}$ с весами $\\theta^V$ и $\\theta^{\\mu}$ и целевые сети $V'$ и $\\pi'$: $\\theta^{V'} \\gets \\theta^V$ и $\\theta^{\\mu'} \\gets \\theta^{\\mu}$\n",
    "2. Устанавливаем число эпизодов обучения $M$ и для каждого эпизода выполняем:\n",
    "3. Проходим траекторию, пока не достигнем конечного состояния.\n",
    "    - Находясь в состоянии $s_t$ действуем в силу текущей политики и выбираем действие $a_t = \\pi^{\\mu}(s_t)|_{\\theta^{\\mu}}$\n",
    "    - Выполняем действие $a_t$ и переходим в состояние $s_{t+1}$ и получаем награду $r_t$\n",
    "    - В состоянии $s_{t+1}$ действуя в силу текущей политики выбираем действие $a_{t+1} = \\pi^{\\mu}(s_{t+1})|_{\\theta^{\\mu}}$\n",
    "    - Вычисляем $Loss(\\theta^V)=\\big( r_t + \\gamma V^{\\theta}(s_{t+1}) - V^{\\theta}(s_t) \\big)^2$\n",
    "    - Вычисляем $Loss(\\theta^{\\mu}) = \\ln{\\pi^{\\mu}(a_t|s_t)}(r_t + \\gamma V^{\\theta}(s_{t+1}) - V^{\\theta}(s_t))$\n",
    "    - Обновляем веса: </br>\n",
    "    __Внимание!__ У V-функции мы ___минимизируем___ веса, а в политике ___максимизируем_!__ </br>\n",
    "      $\\quad \\quad \\theta^V \\gets \\theta^V - \\alpha \\nabla_{\\theta^V}Loss(\\theta^V)$, </br>\n",
    "      $\\quad \\quad \\theta^{\\mu} \\gets \\theta^{\\mu} + \\beta \\nabla_{\\theta^{\\mu}}Loss(\\theta^{\\mu})$\n",
    "    - Обновляем целевые сети: </br>\n",
    "    $\\quad \\quad \\theta^{V'} \\gets \\tau \\theta^V + (1 - \\tau) \\theta^{V'}$, </br>\n",
    "    $\\quad \\quad \\theta^{\\mu'} \\gets \\tau \\theta^{\\mu} + (1 - \\tau) \\theta^{\\mu'}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa53019a-9db2-4d0d-b4db-ff83f4a1947a",
   "metadata": {
    "id": "aa53019a-9db2-4d0d-b4db-ff83f4a1947a"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"CarRacing-v3\",\n",
    "    continuous=True,\n",
    "    domain_randomize=False,\n",
    "    lap_complete_percent=0.95,\n",
    "    max_episode_steps=1_000,\n",
    "    # render_mode=\"human\",  # Раскомментируйте, чтобы увидеть игру\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18271d-ca54-4985-a588-44009ddf78f9",
   "metadata": {
    "id": "5e18271d-ca54-4985-a588-44009ddf78f9"
   },
   "source": [
    "Чтобы использовать сразу несколько изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f4365e8-977c-4d8e-a5e1-a14c817a1546",
   "metadata": {
    "id": "0f4365e8-977c-4d8e-a5e1-a14c817a1546"
   },
   "outputs": [],
   "source": [
    "env = gym.wrappers.FrameStackObservation(env, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bafbacd-ff98-4300-89bc-820a083fcf29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bafbacd-ff98-4300-89bc-820a083fcf29",
    "outputId": "5f8a3a1a-a7e8-4b4f-bb05-c315c6ab2012"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Box(0, 255, (4, 96, 96, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "# Пример state\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "060d2129-4368-40b3-b160-5a9db790f7e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "060d2129-4368-40b3-b160-5a9db790f7e8",
    "outputId": "f3be63ee-6aa7-4f65-f2fd-1d1fbef7be64"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.82968724  0.45596352  0.7342646 ]\n"
     ]
    }
   ],
   "source": [
    "# Пример action\n",
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e11e0187-7199-43d7-934c-fb6f58573752",
   "metadata": {
    "id": "e11e0187-7199-43d7-934c-fb6f58573752",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3b1b5edd-2355-431a-b69d-ee2ee84a2cf4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Используемое устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cac3b3a-5661-46fe-a4ed-7339e6ceda6c",
   "metadata": {
    "id": "4cac3b3a-5661-46fe-a4ed-7339e6ceda6c"
   },
   "outputs": [],
   "source": [
    "# Основные параметры RL\n",
    "gamma = torch.tensor(0.99).to(device)  # discount_factor\n",
    "num_episodes = 250\n",
    "\n",
    "# Основные параметры DL\n",
    "lr = 1e-4\n",
    "batch_size = 128\n",
    "max_grad_norm = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c27b2a61-c4d3-4406-a160-d5daf7d50a5c",
   "metadata": {
    "id": "c27b2a61-c4d3-4406-a160-d5daf7d50a5c"
   },
   "outputs": [],
   "source": [
    "actor_model = ActorNet().to(device)\n",
    "value_model = ValueNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3e8646b-7422-4de2-8537-d3477c7ae59c",
   "metadata": {
    "id": "b3e8646b-7422-4de2-8537-d3477c7ae59c"
   },
   "outputs": [],
   "source": [
    "# state = transform_state_to_tensor(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4bd2fc9-9f7e-4c3b-ba40-790022eda9c7",
   "metadata": {
    "id": "d4bd2fc9-9f7e-4c3b-ba40-790022eda9c7"
   },
   "outputs": [],
   "source": [
    "# actor_model.get_action_and_log_prob(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f470288-e10e-42a4-b16d-55c8f1a5d8af",
   "metadata": {
    "id": "8f470288-e10e-42a4-b16d-55c8f1a5d8af"
   },
   "outputs": [],
   "source": [
    "opt_actor = torch.optim.AdamW(actor_model.parameters(), lr=lr, fused=True)\n",
    "opt_value = torch.optim.AdamW(value_model.parameters(), lr=lr, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1ca65-31c2-4fcd-ad0d-98e7e6617232",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03a1ca65-31c2-4fcd-ad0d-98e7e6617232",
    "outputId": "29b3ef1d-1211-4244-89b0-bf5dff45634c",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 1/250 [00:11<48:44, 11.75s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean for last 5 episodes is -23.357664233576653\n",
      "Mean for last 50 episodes is -23.357664233576653\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  2%|▏         | 6/250 [01:12<49:04, 12.07s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean for last 5 episodes is -30.43669613159731\n",
      "Mean for last 50 episodes is -29.256857481927202\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  4%|▍         | 11/250 [02:12<47:25, 11.91s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean for last 5 episodes is -33.981671330021754\n",
      "Mean for last 50 episodes is -31.404500140151995\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  5%|▌         | 13/250 [02:36<46:47, 11.85s/it]"
     ]
    }
   ],
   "source": [
    "reward_records = []\n",
    "\n",
    "for episode in trange(num_episodes):\n",
    "\n",
    "    done = False\n",
    "    visited_states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    state, _ = env.reset()\n",
    "\n",
    "    # Play one episode (collect trajectory)\n",
    "    while not done:\n",
    "\n",
    "        state = preprocess_state(state)\n",
    "        state = transform_state_to_tensor(state, device=device)\n",
    "        visited_states.append(state)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action, _ = actor_model.get_action_and_log_prob(state)\n",
    "\n",
    "        state, reward, terminated, truncated, _ = env.step(\n",
    "            action.cpu().numpy().flatten()\n",
    "        )\n",
    "\n",
    "        done = terminated or truncated\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "    # Prepare data\n",
    "    rewards_tensor = torch.tensor(rewards, device=device)\n",
    "\n",
    "    # Train value model\n",
    "    opt_value.zero_grad()\n",
    "\n",
    "    values = value_model(torch.cat(visited_states))\n",
    "    values = values.squeeze()\n",
    "\n",
    "    returns = compute_returns(\n",
    "        rewards=rewards_tensor, values=values, gamma=gamma, device=device\n",
    "    )\n",
    "    advantages = (returns - values).detach()\n",
    "\n",
    "    value_model_loss = F.mse_loss(values, returns)\n",
    "    value_model_loss.backward()\n",
    "\n",
    "    nn.utils.clip_grad_norm_(value_model.parameters(), 0.5)\n",
    "    opt_value.step()\n",
    "\n",
    "    # Train actor model\n",
    "    opt_actor.zero_grad()\n",
    "\n",
    "    _, log_probs_tensor = actor_model.get_action_and_log_prob(torch.cat(visited_states))\n",
    "    # log_probs_tensor = torch.cat(log_probs)\n",
    "\n",
    "    policy_loss = -log_probs_tensor * advantages\n",
    "    policy_loss.sum().backward()\n",
    "\n",
    "    nn.utils.clip_grad_norm_(actor_model.parameters(), 0.5)\n",
    "    opt_actor.step()\n",
    "\n",
    "    reward_records.append(sum(rewards))\n",
    "\n",
    "    if episode % 5 == 0:\n",
    "        print(f\"Mean for last 5 episodes is {np.mean(reward_records[-5:])}\")\n",
    "        print(f\"Mean for last 50 episodes is {np.mean(reward_records[-50:])}\")\n",
    "\n",
    "    # Stop if mean reward for 100 episodes > 475.0\n",
    "    # Naive early stopping\n",
    "    if np.average(reward_records[-100:]) > 475.0:\n",
    "        break\n",
    "\n",
    "print(f\"\\nDone in {episode+1} episodes\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "returns = []\n",
    "next_value = 0  # For terminal state\n",
    "\n",
    "# Work backwards through the episode\n",
    "for t in reversed(range(len(rewards_tensor))):\n",
    "    # If next state is terminal, next_value = 0\n",
    "    if t == len(rewards_tensor) - 1:\n",
    "        returns_t = rewards_tensor[t]\n",
    "    else:\n",
    "        returns_t = rewards_tensor[t] + gamma * rewards_tensor[t + 1]\n",
    "    returns.insert(0, returns_t)"
   ],
   "metadata": {
    "id": "LRI_27FAT7CS"
   },
   "id": "LRI_27FAT7CS",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FP2c2g29UEHL",
    "outputId": "dbe5cf6e-d140-4570-ba2a-b6d2f54774ac"
   },
   "id": "FP2c2g29UEHL",
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 6.7214, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990,  3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,  3.2266,  3.2612, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "         3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990,  3.2266,  3.2612, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990,  3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990,  3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990,  3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990,  3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,  3.2266,\n",
       "         3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990,  3.2266,  3.2612, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990,  3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "         3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990,  3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,  3.2266,  3.2612, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990,  3.2266,  3.2612, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "         3.2266,  3.2612, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990,  3.2266,  3.2612, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990,  3.2266,  3.2612, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,  3.2266,  3.2612,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990,\n",
       "        -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1990, -0.1000],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e80b31-3b3f-4d2a-8711-3693bfd732c9",
   "metadata": {
    "id": "31e80b31-3b3f-4d2a-8711-3693bfd732c9"
   },
   "source": [
    "## Training graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a164cb3-dee4-4216-bde4-816e65cf236e",
   "metadata": {
    "id": "0a164cb3-dee4-4216-bde4-816e65cf236e"
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame(rewards, columns=[\"steps\", \"reward\"])\n",
    "# table = table.iloc[2_000:, :]  # remove exploratory_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b6a63-f5c3-4351-8d1e-c71d3fd35fd4",
   "metadata": {
    "id": "e26b6a63-f5c3-4351-8d1e-c71d3fd35fd4"
   },
   "outputs": [],
   "source": [
    "plt.plot(table.index, table[\"reward\"].rolling(100).mean())\n",
    "plt.xlabel(\"Training episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Average reward per 100 episodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y4A023hEG31F",
   "metadata": {
    "id": "y4A023hEG31F"
   },
   "outputs": [],
   "source": [
    "plt.plot(table.index, table[\"steps\"].rolling(100).mean())\n",
    "plt.xlabel(\"Training episode\")\n",
    "plt.ylabel(\"steps\")\n",
    "plt.title(\"Average steps per 100 episodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf60fcc-1113-4161-9348-3a5a72627b81",
   "metadata": {
    "id": "6bf60fcc-1113-4161-9348-3a5a72627b81"
   },
   "source": [
    "## Анимация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5a274-e857-4301-a17f-55b93e78369e",
   "metadata": {
    "id": "d1c5a274-e857-4301-a17f-55b93e78369e"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"CarRacing-v3\",\n",
    "    continuous=True,\n",
    "    domain_randomize=False,\n",
    "    lap_complete_percent=0.95,\n",
    "    max_episode_steps=5_000,\n",
    "    render_mode=\"human\",  # Раскомментируйте, чтобы увидеть игру\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df198f32-9cdc-4341-940f-45e6308735c8",
   "metadata": {
    "id": "df198f32-9cdc-4341-940f-45e6308735c8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850117a0-f0d8-4533-b842-fbaca3f29e5c",
   "metadata": {
    "id": "850117a0-f0d8-4533-b842-fbaca3f29e5c"
   },
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "\n",
    "done = False\n",
    "score = 0\n",
    "state, _ = env.reset()\n",
    "state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "# n_actions = env.action_space.n\n",
    "# n_observations = len(state)\n",
    "\n",
    "while not done:\n",
    "    env.render()  # Раскомментируйте, чтобы увидеть игру\n",
    "    # with torch.no_grad():\n",
    "    #     # best action\n",
    "    #     action = policy_net_2(state).argmax()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    state = next_state\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "    score += reward\n",
    "\n",
    "env.close()\n",
    "\n",
    "print(f\"Score is: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa91eb-d44d-4603-bff2-a79478d9733f",
   "metadata": {
    "id": "ebaa91eb-d44d-4603-bff2-a79478d9733f"
   },
   "outputs": [],
   "source": [
    "torch.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964da7e-d45b-4269-a0b6-5eb2d826c541",
   "metadata": {
    "id": "c964da7e-d45b-4269-a0b6-5eb2d826c541"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9c0198-f5fd-4d7a-bcca-493e6a895c71",
   "metadata": {
    "id": "dc9c0198-f5fd-4d7a-bcca-493e6a895c71"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "collapsed_sections": [
    "34d8f7fc-271f-41fd-aaad-ce9b4df2d075"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}